# WARNING - Generated by {fusen} from dev/dev_template.Rmd: do not edit by hand # nolint: line_length_linter.

#' Generate Plot Description with AI (Phase 3)
#'
#' This function serves as the "Semantic Generator," combining structure and
#'  statistics to prompt an LLM for a structured description.
#'
#' @param structure Metadata list returned by `extract_structure`.
#' @param stats Statistical profile returned by `profile_data`.
#' @param provider The LLM provider (e.g., "openai", "azure", "anthropic").
#' @param model The specific model to use.
#' @param max_tokens_short_desc Maximum token limit for the short desc 
#' - typically to be used for a chart subtitle
#' @param max_tokens_long_desc Maximum token limit for the short desc 
#' - typically to be used for a long narrative illustration
#' 
#' @return A list containing:
#'   \item{short_desc}{A concise, WCAG-compliant alt text string.}
#'   \item{long_desc}{A detailed analytical description of the visualization.}
#' @importFrom ellmer chat_openai chat_google_gemini chat_anthropic
#' @importFrom ellmer chat_ollama chat_azure_openai
#' @importFrom utils capture.output
#' @importFrom jsonlite fromJSON
#' @export
#' @examples
#'
#' library(ggplot2)
#' p <- ggplot(mtcars, aes(x = wt, y = mpg)) +
#'   geom_point() +
#'   unhcrthemes::theme_unhcr(grid = "Y", axis = "X", axis_title = FALSE) +
#'   labs(
#'     title = "Vehicle Efficiency",
#'     subtitle = "Fuel consumption vs weight",
#'     caption = "Source: mtcars dataset"
#'   ) 
#' story <- generate_description(structure= extract_structure(p),
#'                       stats = profile_data(p),
#'                       provider = "azure",
#'                       model = "gpt-4.1-mini",
#'                       max_tokens_short_desc = 30,
#'                       max_tokens_long_desc= 500 ) 
generate_description <- function(structure,
                                 stats,
                                 provider = NULL,
                                 model = NULL,
                                 max_tokens_short_desc = 30,
                                 max_tokens_long_desc= 500 ) {

  if (!is.null(provider) && provider == "none") {
      return(list(short_desc = "", long_desc = ""))
  }

  
  # Construct Context
context_str <- paste0(
  "PLOT METADATA:\n",
  "Title: ", structure$labels$title, "\n",
  "Subtitle: ", structure$labels$subtitle, "\n",
  "Chart Type: ", paste(unique(structure$geoms), collapse = ", "), "\n",
  "X Variable: ", structure$labels$x, "\n",
  "Y Variable: ", structure$labels$y, "\n\n",
  
  "EXECUTIVE-RELEVANT STATISTICAL PROFILE:\n",
  "Key Patterns & Trends:\n",
  paste(capture.output(print(stats$distributions)), collapse = "\n"), "\n",
  "Strategic Relationships: ",
  paste(names(stats$correlations), 
        sapply(unlist(stats$correlations), function(x) {
          if(abs(x) > 0.7) "Strong" else if(abs(x) > 0.4) "Moderate" else "Weak"
        }),
        sep = ": ", collapse = ", "),
  "\n"
)
  
# ---- Revised prompts for executive impact -----------------------------------
system_prompt <- paste0(
  "You are the Chief Data Storyteller for UNHCR, crafting narratives that mobilize resources and influence strategic decisions. ",
  "Your audience: Senior executives and expert fundraisers who need compelling, evidence-based narratives for donor engagement.\n\n",
  
  "YOUR MANDATE:\n",
  "1. EXTRACT ACTIONABLE INSIGHTS: Identify data points with fundraising implications (funding gaps, success factors, ROI indicators)\n",
  "2. CRAFT INVESTMENT NARRATIVES: Frame findings as opportunities for donor investment with clear impact pathways\n",
  "3. HIGHLIGHT STRATEGIC LEVERS: Identify what variables decision-makers can influence for maximum effect\n",
  "4. PRIORITIZE EXECUTIVE RELEVANCE: Focus on implications for resource allocation, partnership strategy, and risk management\n",
  "5. MAINTAIN CREDIBILITY WITH NUANCE: Balance compelling storytelling with appropriate statistical caveats\n\n",
  
  "NARRATIVE REQUIREMENTS:\n",
  "- SHORT_DESC: Opening hook that grabs attention in donor meetings or executive summaries\n",
  "- LONG_DESC: Convincing case-building narrative structured as: Situation → Complication → Implication → Action\n",
  "- Use power language: 'investment,' 'leverage,' 'scale,' 'impact multiplier,' 'strategic priority'\n",
  "- Reference specific data points as evidence for claims\n",
  "- Connect findings to donor priorities (emergency response, resilience, innovation, accountability)\n\n",
  
  "CRITICAL FORMATTING RULES:\n",
  "- ABSOLUTELY NO markdown, asterisks, or thinking tags\n",
  "- Clean plain text only, ready for executive presentations\n",
  "- Write in active voice with confident tone\n",
  "- Quantify impacts where possible (e.g., 'A 10% increase in X correlates with 15% improvement in Y')\n\n",
  
  "OUTPUT STRUCTURE:\n",
  "1) 'short_desc': Maximum-impact opening statement (", max_tokens_short_desc, " token limit)\n",
  "   Formula: '[Chart type] revealing [key strategic insight] with [quantified impact] implications for [specific donor/operational priority]'\n",
  "2) 'long_desc': Persuasive narrative for resource mobilization (", max_tokens_long_desc, " token limit)\n",
  "   Structure:\n",
  "   - Opening attention-grabber\n",
  "   - 2-3 key data-backed insights with fundraising angles\n",
  "   - Strategic recommendations framed as investment opportunities\n",
  "   - Closing call-to-action for decision-makers\n\n",
  
  "OUTPUT FORMAT (NON-NEGOTIABLE):\n",
  "- Return ONLY a JSON object with keys 'short_desc' and 'long_desc'\n",
  "- No additional text, explanations, or formatting\n"
)

prompt <- paste0(
  "EXECUTIVE BRIEFING REQUEST:\n\n",
  
  "CONTEXT FOR RESOURCE MOBILIZATION:\n",
  context_str, "\n\n",
  
  "SPECIFIC EXECUTIVE NEEDS:\n",
  "• How can these insights attract major donor funding?\n",
  "• What strategic decisions should these findings trigger?\n",
  "• Which data points are most compelling for partnership pitches?\n",
  "• What risks or opportunities require immediate executive attention?\n\n",
  
  "TASK: Generate a JSON object with two executive-ready narratives.\n",
  "1. SHORT_DESC: Attention-grabbing headline for fundraising materials\n",
  "2. LONG_DESC: Persuasive narrative to secure donor commitment\n",
  "Respect strict token limits: ", max_tokens_short_desc, " and ", max_tokens_long_desc, " tokens respectively."
)
  

  # Logic to select provider
  # (duplicated from generate_plot_story for now to adhere to modularity)
  if (is.null(provider)) {
    if (!is.na(Sys.getenv("AZURE_OPENAI_ENDPOINT", unset = NA_character_))) {
      provider <- "azure"
    } else if (!is.na(Sys.getenv("OPENAI_API_KEY", unset = NA_character_))) {
      provider <- "openai"
    } else if (!is.na(Sys.getenv("GEMINI_API_KEY", unset = NA_character_))) {
      provider <- "gemini"
    } else if (!is.na(Sys.getenv("ANTHROPIC_API_KEY", unset = NA_character_))) {
      provider <- "anthropic"
    } else {
      stop("No supported API key found.")
    }
  }

  provider <- tolower(provider)
  if (is.null(model)) {
    model <- switch(provider,
      openai = "gpt-4o-mini",
      gemini = "gemini-2.0-flash",
      anthropic = "claude-3-5-sonnet-latest",
      ollama = "deepseek-r1",
      azure = "gpt-4",
      stop("Invalid provider")
    )
  }

  chat <- switch(provider,
    openai = ellmer::chat_openai(
      model = model,
      system_prompt = system_prompt
    ),
    azure = {
      azure_key <- Sys.getenv("AZURE_OPENAI_API_KEY")
      azure_endpoint <- Sys.getenv("AZURE_OPENAI_ENDPOINT")
      azure_version <- Sys.getenv("AZURE_OPENAI_API_VERSION")
      ellmer::chat_azure_openai(
        system_prompt = system_prompt,
        model = model,
        api_version = azure_version,
        endpoint = azure_endpoint,
        api_key = azure_key
      )
    },
    gemini = ellmer::chat_google_gemini(
      model = model,
      system_prompt = system_prompt,
      api_key = Sys.getenv("GEMINI_API_KEY")
    ),
    anthropic = ellmer::chat_anthropic(
      model = model,
      system_prompt = system_prompt
    ),
    ollama = ellmer::chat_ollama(model = model, system_prompt = system_prompt),
    stop("Invalid provider")
  )

  response <- tryCatch({
    chat$chat(prompt)
  }, error = function(e) {
    paste("Error invoking AI provider:", e$message)
  })

  # Parse JSON
  # Clean potential markdown code blocks if the model insists on adding them
  cleaned_json <- gsub("^```json\\s*|\\s*```$", "", response)

  tryCatch({
    jsonlite::fromJSON(cleaned_json)
  }, error = function(e) {
    list(short_desc = "Error parsing JSON", long_desc = response)
  })
}
