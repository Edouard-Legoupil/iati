---
title: "IATI Visualisation"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r developmenttest, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message=FALSE, 
  warning=FALSE,
  fig.width = 8,
  fig.asp = 0.718,
  out.width = "90%"
)
library(testthat) 
library(ggplot2)
library(dplyr)
library(tidyverse)
library(scales)
library(unhcrthemes)
# Load already included functions
pkgload::load_all(export_all = FALSE)
```



# Using Language Models to build data stories

The AI reporting toolkit uses a modular architecture to analyze ggplot2 objects and generate context-aware narratives. This approach ensures that the description is grounded in the actual visual structure and data of the plot.

1.  **Phase 1: Structural Extractor (`extract_structure`)**
    Interrogates the rendered plot object (using `ggplot_build`) to retrieve "trained" metadata, such as exact axis ranges, visible labels, and legend mappings. This is the "ground truth" of what the user sees.

2.  **Phase 2: Statistical Profiler (`profile_data`)**
    Summarizes the underlying data distributions and, where appropriate (e.g., scatterplots), calculates statistical relationships like correlations. This provides the "data context" that might not be immediately obvious visually.

3.  **Phase 3: Semantic Generator (`generate_description`)**
    Combines the structural metadata and statistical profile into a structured prompt for the LLM. It returns a JSON object containing a WCAG-compliant short description (alt text) and a detailed long description.

## clean_llm_response

```{r function-clean_llm_response}
#' Clean LLM Response
#'
#' Remove thinking tags, markdown, and other artifacts from LLM responses
#' Useful for Local Open Source Reasoning Small Language Model
#'
#' @param response Character string from LLM response
#' @param keep_punctuation boolean
#' @return Cleaned character string
#' @export
clean_llm_response <- function(response, keep_punctuation = TRUE) {
  if (!is.character(response)) {
    return(response)
  }

  # Split into lines
  lines <- strsplit(response, "\n")[[1]]

  # Find thinking tag boundaries
  think_start <- which(grepl("<think>", lines, ignore.case = TRUE))
  think_end <- which(grepl("</think>", lines, ignore.case = TRUE))

  # Remove ALL lines between thinking tags (inclusive)
  if (length(think_start) > 0 && length(think_end) > 0) {
    remove_indices <- integer(0)
    for (i in seq_along(think_start)) {
      if (think_start[i] <= think_end[i]) {
        remove_indices <- c(remove_indices, think_start[i]:think_end[i])
      }
    }
    if (length(remove_indices) > 0) {
      lines <- lines[-remove_indices]
    }
  }

  # Combine back
  response <- paste(lines, collapse = " ")

  # Remove all non-ASCII characters
  response <- gsub("[^\x20-\x7E]", "", response)

  # Remove common LLM artifacts and introductory phrases
  response <- gsub(
    "^(Sure|Certainly|Okay|Here|First).*?(:|\\.)\\s*",
    "",
    response,
    ignore.case = TRUE
  )
  response <- gsub(
    "^(As an AI|I am an AI|I'm a).*?\\.\\s*",
    "",
    response,
    ignore.case = TRUE
  )
  response <- gsub(
    "^(My role includes|This includes).*?\\.\\s*",
    "",
    response,
    ignore.case = TRUE
  )
  response <- gsub(
    "^(Aligning with constraints).*?\\.\\s*",
    "",
    response,
    ignore.case = TRUE
  )

  # Remove markdown formatting
  response <- gsub("\\*\\*|\\*|__|_", "", response)
  response <- gsub("\\[.*?\\]\\(.*?\\)", "", response)
  response <- gsub("#+\\s*", "", response)
  response <- gsub("`{1,3}", "", response)

  # Remove excessive whitespace
  response <- gsub("\\s+", " ", response)
  response <- trimws(response)

  # If empty after cleaning, provide fallback
  if (nchar(response) == 0) {
    return("Unable to generate story from this visualization.")
  }

  response
}
```

```{r example-clean_llm_response}
response <- paste(
  "<think>",
  "First, I'm a humanitarian data visualization expert. My role includes",
  "extracting insights from visualizations, creating accessible narratives,",
  "highlighting patterns relevant to aid efforts, using clear language with",
  "emotional resonance.",
  "Aligning with constraints: Use plain language, be concise and impactful.",
  "Don't rehash every detail; build narrative depth around 2 key insights",
  "maximum in under 30 tokens.",
  "</think>",
  "This visualization tracks a relationship potentially critical for",
  "humanitarian logistics: higher fuel consumption versus increased weight.",
  "车辆设计"
)
clean_llm_response(response)
```

```{r tests-clean_llm_response}
test_that("clean_llm_response works", {
  expect_true(inherits(clean_llm_response, "function"))
})
```

## extract_structure

```{r function-extract_structure}
#' Extract Plot Structure and Metadata 
#'
#' This function  extracts visual metadata from a ggplot object 
#' by forcing a render build.
#' Unlike simple label extraction, this captures the "trained" ranges and
#' legend mappings that are actually displayed to the user.
#'
#' @param p A `ggplot` object.
#' @return A list containing:
#'   \item{labels}{Title, subtitle, caption, and axis labels.}
#'   \item{ranges}{Exact x and y ranges for each panel (trained).}
#'   \item{guides}{Mapping of visuals (color/shape) to data values.}
#'   \item{geoms}{List of geometric layers used.}
#' @importFrom ggplot2 ggplot_build get_guide_data
#' @importFrom purrr map map_chr
#' @export
extract_structure <- function(p) {
  if (is.null(p)) return(NULL)

  # Force layout build to get trained ranges
  built <- ggplot2::ggplot_build(p)

  # Extract trained axis ranges (handling facets)
  layout_ranges <- built$layout$panel_params |>
    purrr::map(function(panel) {
      list(
        x_range = panel$x.range,
        y_range = panel$y.range
      )
    })

  # Decode legends using get_guide_data (available in ggplot2 >= 3.5.0)
  guides_map <- tryCatch({
    ggplot2::get_guide_data(p)
  }, error = function(e) {
    NULL
  })

  # Basic geoms
  geoms <- purrr::map_chr(p$layers, ~ class(.x$geom)[1])

  list(
    labels = p$labels,
    ranges = layout_ranges,
    guides = guides_map,
    geoms = geoms,
    scales = p$scales$scales
  )
}
```

```{r example-extract_structure}
 
```

```{r tests-extract_structure}
test_that("extract_structure works", {
  expect_true(inherits(extract_structure, "function"))
})
```


## profile_data

```{r function-profile_data}
#' Profile Plot Data 
#'
#' This function generates a statistical profile of the data used in the plot
#'  to provide context for the AI.
#'
#' @details
#' It performs two main tasks:
#' 1. **Distribution Analysis**: Uses `skimr::skim()` to summarize variables
#'    mapped in the plot.
#' 2. **Correlation Check**: For scatterplots (`geom_point`), it calculates
#'    Pearson correlations to help the AI identify relationships.
#'
#' @param p A `ggplot` object.
#' @return A list containing:
#'   \item{distributions}{A `skim_df` object summarizing mapped variables.}
#'   \item{correlations}{A list of correlation coefficients (if applicable).}
#' @importFrom skimr skim
#' @importFrom stats cor
#' @export
profile_data <- function(p) {
  if (is.null(p)) return(NULL)

  # Handle waiver data (when data is in layers, not global)
  if (inherits(p$data, "waiver")) {
    # Try to find data in the first layer with a data frame
    found_data <- FALSE
    for (layer in p$layers) {
      if (!inherits(layer$data, "waiver") && is.data.frame(layer$data)) {
        df <- layer$data
        found_data <- TRUE
        break
      }
    }
    if (!found_data) {
       return(list(
        distributions = skimr::skim(data.frame(Message = "No data found in plot object")),
        correlations = list()
      ))
    }
  } else {
    df <- p$data
  }
  
  if (is.null(df)) return(NULL)

  # Distribution analysis using skimr
  # We focus on variables actually mapped in aes
  mapped_vars <- unique(unlist(purrr::map(p$mapping, all.vars)))
  mapped_vars <- mapped_vars[mapped_vars %in% names(df)]

  if (length(mapped_vars) > 0) {
    df_mapped <- df[mapped_vars]
  } else {
    df_mapped <- df
  }

  # Capture skimr output
  dist_summary <- skimr::skim(df_mapped)

  # Correlation check for Scatterplots
  correlations <- list()
  has_points <- any(sapply(p$layers, function(l) inherits(l$geom, "GeomPoint")))

  if (has_points && "x" %in% names(p$mapping) && "y" %in% names(p$mapping)) {
    x_vars <- all.vars(p$mapping$x)
    y_vars <- all.vars(p$mapping$y)

    if (length(x_vars) == 1 && length(y_vars) == 1) {
      x_var <- x_vars
      y_var <- y_vars

      # Check if they exist in data and are numeric
      if (x_var %in% names(df) && y_var %in% names(df) &&
            is.numeric(df[[x_var]]) && is.numeric(df[[y_var]])) {
        cor_val <- stats::cor(df[[x_var]], df[[y_var]], use = "complete.obs")
        correlations[[paste(x_var, "vs", y_var)]] = cor_val
      }
    }
  }

  list(
    distributions = dist_summary,
    correlations = correlations
  )
}
```

```{r example-profile_data}
p <- ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  unhcrthemes::theme_unhcr(grid = "Y", axis = "X", axis_title = FALSE) +
  labs(
    title = "Vehicle Efficiency",
    subtitle = "Fuel consumption vs weight",
    caption = "Source: mtcars dataset"
  )

profile_data(p)
```

```{r tests-profile_data}
test_that("profile_data works", {
  expect_true(inherits(profile_data, "function"))
})
```

## generate_description

```{r function-generate_description}
#' Generate Plot Description with AI (Phase 3)
#'
#' This function serves as the "Semantic Generator," combining structure and
#'  statistics to prompt an LLM for a structured description.
#'
#' @param structure Metadata list returned by `extract_structure`.
#' @param stats Statistical profile returned by `profile_data`.
#' @param provider The LLM provider (e.g., "openai", "azure", "anthropic").
#' @param model The specific model to use.
#' @param max_tokens_short_desc Maximum token limit for the short desc 
#' - typically to be used for a chart subtitle
#' @param max_tokens_long_desc Maximum token limit for the short desc 
#' - typically to be used for a long narrative illustration
#' 
#' @return A list containing:
#'   \item{short_desc}{A concise, WCAG-compliant alt text string.}
#'   \item{long_desc}{A detailed analytical description of the visualization.}
#' @importFrom ellmer chat_openai chat_google_gemini chat_anthropic
#' @importFrom ellmer chat_ollama chat_azure_openai
#' @importFrom utils capture.output
#' @importFrom jsonlite fromJSON
#' @export
generate_description <- function(structure,
                                 stats,
                                 provider = NULL,
                                 model = NULL,
                                 max_tokens_short_desc = 30,
                                 max_tokens_long_desc= 500 ) {

  if (!is.null(provider) && provider == "none") {
      return(list(short_desc = "", long_desc = ""))
  }

  # Construct Context
  context_str <- paste0(
    "PLOT METADATA:\n",
    "Title: ", structure$labels$title, "\n",
    "Subtitle: ", structure$labels$subtitle, "\n",
    "Geoms: ", paste(unique(structure$geoms), collapse = ", "), "\n",
    "X Label: ", structure$labels$x, "\n",
    "Y Label: ", structure$labels$y, "\n\n",

    "STATISTICAL PROFILE:\n",
    "Distributions:\n",
    paste(capture.output(print(stats$distributions)), collapse = "\n"), "\n",
    "Correlations: ",
    paste(names(stats$correlations), unlist(stats$correlations),
          sep = ": ", collapse = ", "),
    "\n"
  )


  # ---- prompts with explicit hard limits -----------------------------------
  # We instruct the model to strictly respect the per-field token budgets
  system_prompt <- paste0(
    "You are a Senior Humanitarian Data Storyteller for UNHCR. ",
    "Your goal is to influence decision-makers by turning data into a 'Cause and Effect' narrative.\n\n",
    "Your role is to: \n",
    "1. Extract, from a given dataset and its visualization parameters, key operational and fund raising insights with quotable and specific data points \n",
    "2. Create compelling, accessible narratives tailored for a humanitarian proposal writer audience \n",
    "3. Highlight patterns, trends, and implications to consider when looking for funding opportunities and designing new proposals or evaluation studies \n",
    "4. Adapt interpretation depth based on available data and context \n",
    "5. Use clear, plain, WCAG-compliant language with appropriate practical recommendations \n\n",
    
    "CRITICAL INSTRUCTIONS:\n",
    "- DO NOT include any thinking tags like <think> or </think> in your response\n",
    "- DO NOT use markdown formatting, asterisks, or special characters\n",
    "- Provide ONLY the final narrative text\n",
    "- Your response should be clean plain text ready for display\n\n",
    "Your task is to generate two outputs for a given data visualization:\n",
    "1) 'short_desc': A WCAG-compliant alt text following the formula ",
    "'[Chart Type] of [Variables], where [Trend/Key Insight]'.\n",
    "2) 'long_desc': A detailed statistical analysis and context description.\n\n",
    "HARD LIMITS (must not be exceeded):\n",
    "- short_desc: <= ", max_tokens_short_desc, " tokens.\n",
    "- long_desc:  <= ", max_tokens_long_desc,  " tokens.\n",
    "Tokens are defined approximately as whitespace-delimited units. ",
    "If in doubt, be shorter. Do not include metadata or explanations.\n\n",
    "OUTPUT FORMAT (STRICT):\n",
    "- Return a single JSON object with keys 'short_desc' and 'long_desc'.\n",
    "- Do NOT wrap the JSON in markdown code fences.\n",
    "- Do NOT include any additional text before or after the JSON."
  )

  prompt <- paste0(
    "Context:\n", context_str, "\n\n",
    "Task: Produce the JSON object with 'short_desc' and 'long_desc' ",
    "respecting the hard token limits above."
  )
  
  

  # Logic to select provider
  # (duplicated from generate_plot_story for now to adhere to modularity)
  if (is.null(provider)) {
    if (!is.na(Sys.getenv("AZURE_OPENAI_ENDPOINT", unset = NA_character_))) {
      provider <- "azure"
    } else if (!is.na(Sys.getenv("OPENAI_API_KEY", unset = NA_character_))) {
      provider <- "openai"
    } else if (!is.na(Sys.getenv("GEMINI_API_KEY", unset = NA_character_))) {
      provider <- "gemini"
    } else if (!is.na(Sys.getenv("ANTHROPIC_API_KEY", unset = NA_character_))) {
      provider <- "anthropic"
    } else {
      stop("No supported API key found.")
    }
  }

  provider <- tolower(provider)
  if (is.null(model)) {
    model <- switch(provider,
      openai = "gpt-4o-mini",
      gemini = "gemini-2.0-flash",
      anthropic = "claude-3-5-sonnet-latest",
      ollama = "deepseek-r1",
      azure = "gpt-4",
      stop("Invalid provider")
    )
  }

  chat <- switch(provider,
    openai = ellmer::chat_openai(
      model = model,
      system_prompt = system_prompt
    ),
    azure = {
      azure_key <- Sys.getenv("AZURE_OPENAI_API_KEY")
      azure_endpoint <- Sys.getenv("AZURE_OPENAI_ENDPOINT")
      azure_version <- Sys.getenv("AZURE_OPENAI_API_VERSION")
      ellmer::chat_azure_openai(
        system_prompt = system_prompt,
        model = model,
        api_version = azure_version,
        endpoint = azure_endpoint,
        api_key = azure_key
      )
    },
    gemini = ellmer::chat_google_gemini(
      model = model,
      system_prompt = system_prompt,
      api_key = Sys.getenv("GEMINI_API_KEY")
    ),
    anthropic = ellmer::chat_anthropic(
      model = model,
      system_prompt = system_prompt
    ),
    ollama = ellmer::chat_ollama(model = model, system_prompt = system_prompt),
    stop("Invalid provider")
  )

  response <- tryCatch({
    chat$chat(prompt)
  }, error = function(e) {
    paste("Error invoking AI provider:", e$message)
  })

  # Parse JSON
  # Clean potential markdown code blocks if the model insists on adding them
  cleaned_json <- gsub("^```json\\s*|\\s*```$", "", response)

  tryCatch({
    jsonlite::fromJSON(cleaned_json)
  }, error = function(e) {
    list(short_desc = "Error parsing JSON", long_desc = response)
  })
}
```

```{r example-generate_description}
p <- ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  unhcrthemes::theme_unhcr(grid = "Y", axis = "X", axis_title = FALSE) +
  labs(
    title = "Vehicle Efficiency",
    subtitle = "Fuel consumption vs weight",
    caption = "Source: mtcars dataset"
  ) 
story <- generate_description(structure= extract_structure(p),
                      stats = profile_data(p),
                      provider = "azure",
                      model = "gpt-4.1-mini",
                      max_tokens_short_desc = 30,
                      max_tokens_long_desc= 500 ) 
```

```{r tests-generate_description}
test_that("generate_description works", {
  expect_true(inherits(generate_description, "function"))
})
```

## generate_plot_story


```{r function-generate_plot_story}
#' Generate Humanitarian Data Story from ggplot
#'
#' This function takes a ggplot2 object and generates a storytelling narrative.
#' It now uses a modular architecture (extract_structure,
#' profile_data, generate_description).
#'
#' @param plot A `ggplot` object.
#' @param max_tokens Max tokens for description.
#' @param provider LLM provider.
#' @param model LLM model.
#' @param max_tokens_short_desc Maximum token limit for the short desc 
#' - typically to be used for a chart subtitle
#' @param max_tokens_long_desc Maximum token limit for the short desc 
#' - typically to be used for a long narrative illustration
#'
#' @return A list containing `$short_desc` and `$long_desc`.
#' @export
generate_plot_story <- function(plot,
                                max_tokens = 300,
                                provider = NULL,
                                model = NULL,
                                max_tokens_short_desc = 30,
                                max_tokens_long_desc= 500) {

  if (is.null(plot) || !inherits(plot, "ggplot")) {
    return(list(
      short_desc = "Invalid input",
      long_desc = "Plot is NULL or not a ggplot object."
    ))
  }

  # Phase 1: Structure
  structure <- extract_structure(plot)

  # Phase 2: Profile
  stats <- profile_data(plot)

  # Phase 3: Semantic Generation
  description <- generate_description(
    structure,
    stats,
    provider,
    model,
    max_tokens_short_desc,
    max_tokens_long_desc
  )

  description
}
```
 

```{r example-generate_plot_story, eval=FALSE}
 
p <- ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  unhcrthemes::theme_unhcr(grid = "Y", axis = "X", axis_title = FALSE) +
  labs(
    title = "Vehicle Efficiency",
    subtitle = "Fuel consumption vs weight",
    caption = "Source: mtcars dataset"
  )

#generate_plot_story(p, provider = "ollama", model = "deepseek-r1")

story <- generate_plot_story(
  p,
  provider = "azure",
  model = "gpt-4.1-mini",
  max_tokens_short_desc = 30,
  max_tokens_long_desc= 500
)
# To use as subtitle:
p + ggplot2::labs(subtitle = story$short_desc)
```

```{r tests-generate_plot_story}
test_that("generate_plot_story works", {
  expect_true(inherits(generate_plot_story, "function"))
})
```




# Report Rendering

## slugify

```{r function-slugify}
#' slugify
#' 
#' Convert string to slug
#' 
#' @param x the string
#' 
#' @return slugified string
#' @importFrom stringr str_to_lower str_replace_all str_remove_all str_squish
#' @importFrom stringi stri_enc_toutf8
#' @export
slugify <- function(x) {
  x |>
    stringi::stri_enc_toutf8() |>
    # Remove extra whitespace first
    stringr::str_squish() |>
    # Convert to lowercase
    stringr::str_to_lower() |>
    # Replace accented characters with their ASCII equivalents
    stringr::str_replace_all("[àáâãäå]", "a") |>
    stringr::str_replace_all("[èéêë]", "e") |>
    stringr::str_replace_all("[ìíîï]", "i") |>
    stringr::str_replace_all("[òóôõöø]", "o") |>
    stringr::str_replace_all("[ùúûü]", "u") |>
    stringr::str_replace_all("[ñ]", "n") |>
    stringr::str_replace_all("[ç]", "c") |>
    stringr::str_replace_all("[ýÿ]", "y") |>
    stringr::str_replace_all("[ž]", "z") |>
    # Remove all non-alphanumeric characters except spaces, underscores, AND hyphens
    stringr::str_replace_all("[^a-z0-9\\s_-]", "") |>
    # Replace spaces and underscores with hyphens
    stringr::str_replace_all("[\\s_]+", "-") |>
    # Remove consecutive hyphens
    stringr::str_replace_all("-+", "-") |>
    # Remove leading/trailing hyphens
    stringr::str_remove_all("^-|-$")
}
```
  
```{r example-slugify}
strings <- c("Café au Lait", "Niño Español", "Data_Science_Project", "--test--string--")
slugify(strings)
```
  
```{r tests-slugify}
test_that("slugify works", {
  expect_true(inherits(slugify, "function")) 
})
```
 
  
# Template

## template_prez
    
```{r function-template_prez}

# usethis::use_rmarkdown_template(
#   template_name = "iati_prez",
#   template_dir = NULL,
#   template_description = "UNHCR IATI",
#   template_create_dir = TRUE
# )


#' Generate a summary powerpoint
#' 
#' @param year A numeric value or a vector of numeric value to filter on year. Note that data pre-2022 are using a different set of indicators
#' @param ctr_name A character vector corresponding to the name of the country.
#' @param folder folder within your project where to put the generated report. 
#'              Folder will be created if it does not exist
#' 
#' @importFrom unhcrdown pptx_slides
#' @importFrom dplyr filter select pull
#' @importFrom rmarkdown render
#' @importFrom here here
#' @importFrom countrycode countrycode
#' @importFrom stringr str_replace_all
#' 
#' @return nothing the file for the report is generated
#' 
#' @export 
#'
template_prez <- function(year = 2025,
                          ctr_name,   
                          folder = "Prez") {
  
  ## Create the outfolder if it does not exist
  output_dir <- paste0(getwd(),"/",folder)
  if (!dir.exists(output_dir)) {dir.create(output_dir)}
  
  rmarkdown::render(
    system.file("rmarkdown/templates/iati_prez/skeleton/skeleton.Rmd", package = "iati"),
    output_file = here::here(folder, paste0('Strategic_Moment_of_Reflection-',
                                            stringr::str_replace_all( 
                           countrycode::countrycode(ctr_name,
                                               origin = "country.name",
                                               destination = "unhcr.region"), " ", "_"),
                                            "__",
                                            stringr::str_replace_all( ctr_name, " ", "_"),
                        '-', year, '.pptx') ),
    params = list(ctr_name = ctr_name, 
                  year = year)  )
}
```
  
```{r example-template_prez}

## generate for one country
# iati::template_prez(year = 2025, 
#                     ctr_name = "Brazil",
#                     folder = "dev/Prez")

# ## Generate for all operation specific region
# reg <- iati::dataActivity |>
#   dplyr::select( unhcr_region) |>
#   dplyr::filter(! is.na(unhcr_region)) |>
#   dplyr::distinct() |>
#   dplyr::pull() 
# 
# thisfolder <- "dev/SMR" 
# 
# for (region in reg) { 
#       cat(paste0( region,   "\n"))
#
#       # region <- "The Americas"   
#       countries <- iati::dataActivity |>
#         dplyr::filter( unhcr_region ==  region) |>
#         dplyr::select(ctr_name) |>
#         dplyr::distinct() |>
#         dplyr::pull() 
#       
#       for ( ctr in countries) {
#         cat(paste0("Generating for ", ctr, "\n"))
#         iati::template_prez(year = 2025,
#                             ctr_name = ctr,
#                             folder =  thisfolder)  
#         }
#     }
```
  
```{r tests-template_prez}
test_that("template_prez works", {
  expect_true(inherits(template_prez, "function")) 
})
```

## template_compare
    
```{r function-template_compare}

# usethis::use_rmarkdown_template(
#   template_name = "iati_compare",
#   template_dir = NULL,
#   template_description = "Compare",
#   template_create_dir = TRUE
# )


#' Generate a summary powerpoint
#' 
#' @param year A numeric value or a vector of numeric value to filter on year. Note that data pre-2022 are using a different set of indicators
#' @param ctr_name A character vector corresponding to the name of the country.
#' @param folder folder within your project where to put the generated report. 
#'              Folder will be created if it does not exist
#' 
#' @importFrom unhcrdown pptx_slides
#' @importFrom dplyr filter select pull
#' @importFrom rmarkdown render
#' @importFrom here here
#' @importFrom countrycode countrycode
#' @importFrom stringr str_replace_all
#' 
#' @return nothing the file for the report is generated
#' 
#' @export 
#'
template_compare <- function(year = 2025,
                          folder = "Compare") {
  
  ## Create the outfolder if it does not exist
  output_dir <- paste0(getwd(),"/",folder)
  if (!dir.exists(output_dir)) {dir.create(output_dir)}
  
  rmarkdown::render(
    system.file("rmarkdown/templates/iati_compare/skeleton/skeleton.Rmd", package = "iati"),
    output_file = here::here(folder, paste0('Result_Resource',
                                            '-', year, '.pptx') ),
    params = list(year = year)  )
}
```
  
```{r example-template_compare} 
# iati::template_compare(year = 2025, folder = "dev/Result")
```
  
```{r tests-template_compare}
test_that("template_compare works", {
  expect_true(inherits(template_compare, "function")) 
})
```
    


```{r development-inflate, eval=FALSE}
# Inflate the package

# You're one inflate from paper to box.
# Build your package from this very Rmd using `fusen::inflate()`
# 
# - Verify your `"DESCRIPTION"` file has been updated
# - Verify your function is in `"R/"` directory
# - Verify your test is in `"tests/testthat/"` directory
# - Verify this Rmd appears in `"vignettes/"` directory

# Keep eval=FALSE to avoid infinite loop in case you hit the knit button
# Execute in the console directly
fusen::inflate(flat_file = "dev/dev_template.Rmd", clean= TRUE, vignette_name = " -- Report Utilities")
```



